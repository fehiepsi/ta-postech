
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass{article}

    
    
    \usepackage{graphicx} % Used to insert images
    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{color} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    

    

    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=blue,
      linkcolor=darkorange,
      citecolor=darkgreen,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    
    
    

    
    \subsection*{Analysis I - homework - week
11}\label{analysis-i---homework---week-11}
\addcontentsline{toc}{subsection}{Analysis I - homework - week 11}

    \textbf{1.} $(a)$ Suppose that $f : \mathbb{R}^n \to \mathbb{R}^m$ is of
class $C^1$ and $Df (x_0 )$ has rank $m$. This means that $Df (x_0 )$ as
a linear map is onto. Then show that there is a neighborhood of $f(x_0)$
lying in the image of $f$.

$(b)$ Suppose $f : \mathbb{R}^n \to \mathbb{R}^m$ is $C^1$ and
$Df (x_0 )$ is one-to-one. Show $f$ is one-to-one on a neighborhood of
$x_0$.

    \textbf{Sketch of proof.} \emph{Lemma.} (Generalization of
Straightening-out Theorem) Let $f: \mathbb{R}^n \to \mathbb{R}^m$,
$n\ge m$, $f \in C^1$. Suppose $f(x_0) = 0$ and $Df(0)$ has rank $m$.
Then there is an open set $U$, an open set $V$ containing $x_0$, and a
function $h:U\to V$ of class $C^1$, with inverse $h^{-1}:V\to U$ of
class $C^1$, such that for all $(x_1,\ldots,x_n)\in U$, we have
\[f(h(x_1,\ldots,x_n)) = (x_{n-m+1},\ldots,x_n).\]

For a proof of this lemma, see Exercise 7.3 in the textbook and imitate
the proof of Straightening-out Theorem without any much modification
(replace $\mathbb{R}^{n-1}\times \mathbb{R}$ by
$\mathbb{R}^{n-m}\times \mathbb{R}^m$).

$(a)$ By $Df(x_0)$ has rank $m$, we have $n \ge m$. Put
$g(x) = f(x) - f(x_0)$, so $g(x_0) = 0$. Moreover, $Dg(x_0) = Df(x_0)$,
so $Dg(x_0)$ has rank $m$. By the above lemma, there is an open set $U$,
an open set $V$ containing $x_0$, and a surjective function $h:U\to V$
such that for all $(x_1,\ldots,x_n)\in U$, we have
\[g(h(x_1,\ldots,x_n)) = (x_{n-m+1},\ldots,x_n).\]

Show that $f(V)\subset \operatorname{Im}(f)$ is a neighborhood of
$f(x_0)$.

$(b)$ In Linear Algebra, we know that if $Df(x_0)$ is one-to-one then
$Df(x_0)$ has rank $n$ (by
$n = \operatorname{rank}Df(x_0) + \dim \operatorname{Ker}( Df(x_0))$).
So $n\le m$. Apply Theorem 7.4, there are open sets $U$ and $V$ in
$\mathbb{R}^m$ with $f(x_0)\in U$ and a function $g:U\to V$ such that
for all $(x_1,\ldots,x_n)\in f^{-1}(U)$, we have
\[g\circ  f(x_1,\ldots,x_n) = (x_1,\ldots,x_n,0,\ldots,0).\]

Show that $f$ is one-to-one on $f^{-1}(U)$, which is a neighborhood of
$x_0$. $\Box$

    \textbf{2.} Does the function $h$ in Theorem 3 (\emph{Straightening-out
Theorem}) have to be unique? Discuss.

    \textbf{Sketch of proof.} No. For example, let
$f:\mathbb{R}^2 \to \mathbb{R}^2$ be defined by $f(x,y) = x+y$. Consider
$h_1,h_2 :\mathbb{R}^2 \to \mathbb{R}^2$ be defined by
$h_1(x,y) = (x,y -x)$, $h_2(x,y) = (x+1,y-x-1)$. $\Box$

    \textbf{3.} Let $U \subset \mathbb{R}^n$ be open. We say the boundary
$\partial U$ is $C^p$ if for each point $x_0 \in \partial U$ there exist
$r > 0$ and a $C^p$ function $\gamma : \mathbb{R}^{n-1} \to \mathbb{R}$
such that - upon relabeling and reorienting the coordinates axes if
necessary - we have
\[U \cap B(x_0 , r) = \{x \in B(x_0 , r) \mid x_n > \gamma(x_1 , \ldots , x_{n−1})\}.\]

Likewise, $\partial U$ is $C^{\infty}$ if $\gamma$ is $C^{\infty}$
function.

Determine that the following boundaries are $C^1$:

$(a)$ $U := \{(x, y, z) \in \mathbb{R}^3 \mid x + y + z < 0\}$ and its
boundary is
$\partial U := \{(x, y, z) \in \mathbb{R}^3 \mid x + y + z = 0\}$.

$(b)$ $U := \{(x, y) \in \mathbb{R}^2 \mid  x^3 + y^3 < 1\}$ and its
boundary is
$\partial U := \{(x, y) \in \mathbb{R}^2 \mid  x^3 + y^3 = 1\}$.

    \textbf{Sketch of proof.} $(a)$ Consider
$\gamma :\mathbb{R}^2 \to \mathbb{R}$ defined by $\gamma(x,y) = x+y$.

$(b)$ \emph{Note.} The $\gamma$ function needs not to be in $C^p$ of the
whole $\mathbb{R}^{n-1}$, we just require it to be in $C^p$ in a
neighborhood of $(x^0_1,\ldots,x^0_{n-1})$ where
$(x^0_1,\ldots,x^0_{n-1},x^0_n)=x_0 $.

We consider $\gamma :\mathbb{R} \to \mathbb{R}$ defined by
$\gamma(z) = \sqrt[3]{z^3 -1}$. Consider two cases: $x_0 \ne 1$ and
$x_0 = 1$. $\Box$

    \textbf{4.} Show that $dx/dt =\sqrt{x}$, $x(0) = 0$ has two solutions:
\[x(t) = 0 \quad\text{and}\quad x(t) = \begin{cases} 0, & \text{if } t\le 0,\\ t^2/4, &\text{else.}\end{cases}\]

Does this contradict Theorem 6?

    \textbf{Sketch of proof.} This does not contradict Theorem 6, because
the square function $\sqrt{x}$ is not defined on $[-r, r]$ for all
$r > 0$. Moreover, if we consider $\sqrt{x}$ is $\sqrt{|x|}$, then
still, we have another reason: $\sqrt{|x|}$ is not Lipschitz in any
neighborhood of $0$. $\Box$

    \textbf{5.} Consider the equation $dx/dt = 1 + tx$, $x(0) = 0$. Examine
the iteration scheme given in the text to obtain a power series
expression for the solution. Examine the radius of convergence.

    \textbf{Sketch of proof.} Put $f(t,x) = 1 + tx$. Show by induction that
\[x_n(t) = \sum_{i = 1}^{n-1} \frac{t^{2i-1}}{1.3\ldots  (2i-1)}.\]

We obtain a power series expression for the solution:
\[x(t) = \sum_{i = 1}^{\infty} \frac{t^{2i-1}}{1.3\ldots (2i-1)}.\]

Now, we may write $x(t)$ in the following form:
\[x(t) = t\sum_{i = 1}^{\infty} \frac{(t^2)^{i-1}}{1.3\ldots (2i-1)} = t \sum_{i = 0}^{\infty} \frac{(t^2)^i}{1.3\ldots (2i+1)}.\]

The radius of convergence $R$ of $x(t)$ is the square root of the radius
of convergence of the series \[
\sum_{i=0}^{\infty} \frac{s^i}{1.3\ldots (2i+1)}.
\]

By the ratio test, we have
\[\frac{1}{R^2} = \lim_{n\to \infty} \frac{{1.3\ldots  (2n+1)}}{1.3\ldots  (2n+3)} = \lim_{n\to\infty} \frac{1}{2n+3}= 0.\]

So $R = +\infty$. $\Box$

    \textbf{6.} Let $f : \mathbb{R} \times \mathbb{R}^n \to \mathbb{R}^n$ be
a given continuous mapping. Suppose there is a constant $K$ such that
\[\|f (t, x) − f (t, y)\| ≤ K \| x − y\|\] for all $t \in \mathbb{R}$,
$x, y \in \mathbb{R}^n$. Then there is a unique continuously
differentiable map $x : \mathbb{R} \to \mathbb{R}^n$ such that
\[\begin{cases}
x(0) = x_0, & (\text{initial condition}),\\
dx/dt = f(t,x(t)), & (t,x) \in \mathbb{R} \times \mathbb{R}^n.
\end{cases}\]

    \textbf{Sketch of proof.} Let $b > 0$ such that $b < 1/K$. Put
$A = \{\varphi \in \mathcal{C}([0,b], \mathbb{R}^n) \mid \varphi(0) = x_0\}$.
Show that $A$ is a complete metric space. Now, let $F :A \to A$ be
defined by \[ F(\varphi) (t) = x_0 + \int_0^t f(s, \varphi(s))\, ds.\]

We have \[\|F(\varphi) - F(\psi)\| \le Kb \|\varphi -\psi\|.\]

By $Kb < 1$, the contraction mapping principle shows that there exists a
unique $y_0 \in A$ such that $F(y_0) = y_0$. In other words, we have
\[ y_0(t) = x_0 + \int_0^t f(s, y_0(s))\, ds,\] for all $t\in [0,b]$.
Similarly, there exists a unique
$y_1\in \mathcal{C}([b,2b],\mathbb{R}^n)$ such that
\[ y_1(t) = y_0(b) + \int_b^t f(s,y_1(s))\,ds ,\] for all
$t \in [b,2b]$. By an ``induction'' procedure, we get a unique sequence
$\{y_n\}$ such that $y_n \in \mathcal{C}([nb,(n+1)b],\mathbb{R}^n)$ and
\[y_n(t) = y_{n-1}(nb) + \int_{nb}^t f(s,y_n(s))\,ds ,\] for all
$t \in [nb,(n+1)b]$.

Similarly, we get a unique sequence $\{y_{-n}\}$ such that
$y_{-n} \in \mathcal{C}([-nb, (-n+1)b],\mathbb{R}^n)$ and
\[y_{-n}(t) = y_{-n+1}((-n+1)b) + \int_{(-n+1)b}^t f(s,y_{-n}(s))\,ds,\]
for all $t \in [-nb, (-n+1)b]$.

Now, let $x:\mathbb{R}\to \mathbb{R}^n$ be defined by $x(t) = y_n(t)$ if
$t \in [n, n+1)$ for some $n\in \mathbb{Z}$. It is clear that
$x \in \mathcal{C}(\mathbb{R},\mathbb{R}^n)$ because
$y_n(n+1) = y_{n+1}(n+1)$ for all $n\in \mathbb{Z}$. Show that
\[x(t) = x_0 + \int_0^t f(s, x(s))\,ds,\] for all $t\in \mathbb{R}$. So
far we have prove the existence of a solution for the problem. The final
step is to prove the uniqueness. $\Box$

    \textbf{7.} Let $A = (a_{ij})$ be an $n \times n$ matrix and define
$\|A\| := \sup |a_{ij} |$.

$(a)$ Let $A, B$ be $n \times n$ matrices, then
$\|AB \|≤ n\| A\| \|B\|$.

$(b)$ $\|A^m\| ≤ n^{m−1}\| A\|^m$.

$(c)$ Prove that \[e^{A} := \sum_{m=0}^{\infty}\frac{A^m}{m!}\] is
well-defined; that is, every component of
$B_k =\sum_{m=k}^{\infty}\frac{A^m}{m!}$ converges to $0$ as
$k \to \infty$.

    \textbf{Sketch of proof.} $(a)$ We have
$|[AB]_{ij}| = |\sum_{k=1}^n A_{ik}B_{kj}| \le n \|A\| \|B\|$.

$(b)$ Use induction.

$(c)$ We have $\|\cdot \|$ is a norm in the vector space $\mathcal{M}$
of $n\times n$ matrices. Also, this norm makes $\mathcal{M}$ become a
complete norm space. Now, we have
\[\left\|\frac{A^m}{m!}\right\| \le  \frac{n^{m-1} \|A\|^m}{m!}= \frac{(n\|A\|)^m}{n.m!}.\]

By
\[\lim_{m\to \infty} \frac{\frac{(n\|A\|)^{m+1}}{n.(m+1)!}}{\frac{(n\|A\|)^m}{n.m!}} = \lim_{m\to\infty} \frac{n\|A\|}{m+1} = 0,\]
we have the series $\sum_{m=0}^{\infty}\frac{(n\|A\|)^m}{n.m!}$
converges, hence the series $\sum_{m=0}^{\infty}\frac{A^m}{m!}$
converges by the comparison test (here we use the completeness of
$\mathcal{M}$). So $e^A$ is well-defined. $\Box$

    \textbf{8.} Let $A$ be an $n \times n$ matrix and consider the linear
system \[\frac{dx}{dt}= Ax(t),\quad x(t) \in \mathbb{R}^n.\]

Show that a solution is
\[x(t) = e^{tA} x(0),\quad \text{where }e^B =\sum_{m=0}^{\infty}\frac{B^m}{m!}.\]

    \textbf{Sketch of proof.} It is enough to show that for all
$x_0 \in \mathbb{R}$,
\[\tag{*}\lim_{h\to 0} \frac{(e^{(t+h)A}-e^{tA})x_0}{h} = Ae^{tA}x_0.\]

By Problem 7, we have
\[\lim_{h\to 0} \frac{(e^{(t+h)A}-e^{tA})x_0}{h} = \lim_{h\to 0} \left(\sum_{m=0}^{\infty}\frac{[(t+h)^m-t^m]A^m}{m!h}\right)x_0.\]

Show that we can put $x_0$ inside the series to get
\[\lim_{h\to 0} \frac{(e^{(t+h)A}-e^{tA})x_0}{h} = \lim_{h\to 0} \sum_{m=0}^{\infty}\frac{[(t+h)^m-t^m]A^mx_0}{m!h}.\]

The next step is to show the series converges uniformly for
$h\in [-1,1]\backslash \{0\}$.

Recall in proof of HW\#6, Problem 1, we just need $f_n$ converge to $f$
uniformly in a deleted neighborhood of $x$ for an interchange of limits:
\[ \lim_{t\to x}\lim_{n\to\infty} f_n(t) = \lim_{n\to \infty}\lim_{t\to x}f_n(t).\]

So we have \[\begin{aligned}
\lim_{h\to 0} \frac{(e^{(t+h)A}-e^{tA})x_0}{h} &=  \sum_{m=0}^{\infty}\lim_{h\to 0}\frac{[(t+h)^m-t^m]A^mx_0}{m!h}\\
&= \sum_{m=1}^{\infty} \frac{mt^{m-1}A^m x_0}{m!}\\
& = \left(\sum_{m=1}^{\infty} A\frac{t^{m-1}A^{m-1}}{(m-1)!}\right)x_0\\
& = A e^{tA}x_0.
\end{aligned}\]

In the last equality, we can take $A$ outside the series because
$Ab_n \to Ab$ if $b_n \to b$ in $\mathbb{R}^n$. $\Box$

    \textbf{9.} Let
$f (x, y) = x^2 + y^2 + 3y^3 + 8x^4 + x^2 e^x \sin x + 6$. Show that
there exist new coordinates $\xi$, $\eta$, where
\[\xi = \xi(x, y),\quad \eta = \eta(x, y),\] for which
\[f (x, y) = \xi^2 + \eta^2 + 6\] in a neighborhood of $(0, 0)$.

    \textbf{Sketch of proof.} By $Df(0,0) = 0$, we have $(0,0)$ is a
critical point. At $(0,0)$, the Hessian matrix
$\Delta = \begin{bmatrix}-2 & 0 \\ 0 & -2 \end{bmatrix}$. By $-2 < 0$
and $\det (\Delta) = 4 > 0$, $\Delta$ is negative definite, hence the
index of $f$ at $(0,0)$ is $0$. Apply the Morse Lemma, there exist such
new coordinates in a neighborhood of $(0,0)$. $\Box$

    \textbf{10.} Compute the index of the function
$x^2 + y^2 − 7x − 8y + xy + 16 + (x − 2)^3$ at its critical point
$x = 2$, $y = 3$. Discuss the nature of the function near this point.

    \textbf{Sketch of proof.} By $Df(2,3) = 0$, we have $(2,3)$ is a
critical point. At $(2,3)$, the Hessian matrix
$\Delta = \begin{bmatrix}-2 & 1 \\ 1 & -2 \end{bmatrix}$. By \$ -2
\textless{} 0\$ and $\det (\Delta) = 3 > 0$, $\Delta$ is negative
definite, hence the index of $f$ at $(2,3)$ is $0$. Apply the Morse
Lemma, near $(2,3)$ the function is approximately a paraboloid and in
some new coordinate system it is exactly a paraboloid. $\Box$


    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
